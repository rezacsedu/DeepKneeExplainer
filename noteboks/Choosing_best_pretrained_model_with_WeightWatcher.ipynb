{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reza/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## WeightWatcher helps you choose the best pretrained model for your needs.\n",
    "\n",
    "## You can use WeightWatcher to compare several pretrained models and choose the one with the lowest Log Norm.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 8,8\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import VGG\n",
    "import ResNet\n",
    "import numpy as np\n",
    "import os\n",
    "import gradcamutils\n",
    "from DenseNet import densenet\n",
    "from PIL import Image\n",
    "import weightwatcher as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reza/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 352, 320, 1)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 352, 320, 2)       20        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 352, 320, 2)       38        \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 176, 160, 2)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 176, 160, 4)       76        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 176, 160, 4)       148       \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 88, 80, 4)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 88, 80, 8)         296       \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 88, 80, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 88, 80, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 88, 80, 8)         584       \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 44, 40, 8)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 44, 40, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 44, 40, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 44, 40, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 44, 40, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 22, 20, 16)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 22, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 22, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 22, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 22, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 11, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1760)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               901632    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 987,550\n",
      "Trainable params: 987,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/reza/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Model: \"densenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 352, 320, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 176, 160, 8)  392         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 176, 160, 8)  32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 176, 160, 8)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 88, 80, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 88, 80, 8)    32          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 88, 80, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 88, 80, 48)   384         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 88, 80, 48)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 88, 80, 48)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 88, 80, 12)   5184        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 88, 80, 20)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 88, 80, 20)   80          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 88, 80, 20)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 88, 80, 48)   960         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 88, 80, 48)   192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 88, 80, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 88, 80, 12)   5184        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 88, 80, 32)   0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 88, 80, 32)   128         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 88, 80, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 88, 80, 48)   1536        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 88, 80, 48)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 88, 80, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 88, 80, 12)   5184        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 88, 80, 44)   0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 88, 80, 44)   176         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 88, 80, 44)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 88, 80, 48)   2112        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 88, 80, 48)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 88, 80, 48)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 88, 80, 12)   5184        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 88, 80, 56)   0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 88, 80, 56)   224         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 88, 80, 56)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 88, 80, 48)   2688        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 88, 80, 48)   192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 88, 80, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 88, 80, 12)   5184        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 88, 80, 68)   0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 88, 80, 68)   272         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 88, 80, 68)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 88, 80, 48)   3264        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 88, 80, 48)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 88, 80, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 88, 80, 12)   5184        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 88, 80, 80)   0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 88, 80, 80)   320         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 88, 80, 80)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 88, 80, 40)   3200        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 44, 40, 40)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 44, 40, 40)   160         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 44, 40, 40)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 44, 40, 48)   1920        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 44, 40, 48)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 44, 40, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 44, 40, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 44, 40, 52)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 44, 40, 52)   208         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 44, 40, 52)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 44, 40, 48)   2496        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 44, 40, 48)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 44, 40, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 44, 40, 12)   5184        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 44, 40, 64)   0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 44, 40, 64)   256         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 44, 40, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 44, 40, 48)   3072        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 44, 40, 48)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 44, 40, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 44, 40, 12)   5184        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 44, 40, 76)   0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 44, 40, 76)   304         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 44, 40, 76)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 44, 40, 48)   3648        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 44, 40, 48)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 44, 40, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 44, 40, 12)   5184        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 44, 40, 88)   0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 44, 40, 88)   352         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 44, 40, 88)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 44, 40, 48)   4224        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 44, 40, 48)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 44, 40, 48)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 44, 40, 12)   5184        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 44, 40, 100)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 44, 40, 100)  400         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 44, 40, 100)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 44, 40, 48)   4800        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 44, 40, 48)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 44, 40, 48)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 44, 40, 12)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 44, 40, 112)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 44, 40, 112)  448         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 44, 40, 112)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 44, 40, 48)   5376        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 44, 40, 48)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 44, 40, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 44, 40, 12)   5184        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 44, 40, 124)  0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 44, 40, 124)  496         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 44, 40, 124)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 44, 40, 48)   5952        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 44, 40, 48)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 44, 40, 48)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 44, 40, 12)   5184        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 44, 40, 136)  0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 44, 40, 136)  544         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 44, 40, 136)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 44, 40, 48)   6528        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 44, 40, 48)   192         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 44, 40, 48)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 44, 40, 12)   5184        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 44, 40, 148)  0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 44, 40, 148)  592         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 44, 40, 148)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 44, 40, 48)   7104        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 44, 40, 48)   192         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 44, 40, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 44, 40, 12)   5184        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 44, 40, 160)  0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 44, 40, 160)  640         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 44, 40, 160)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 44, 40, 48)   7680        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 44, 40, 48)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 44, 40, 48)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 44, 40, 12)   5184        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 44, 40, 172)  0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 44, 40, 172)  688         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 44, 40, 172)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 44, 40, 48)   8256        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 44, 40, 48)   192         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 44, 40, 48)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 44, 40, 12)   5184        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 44, 40, 184)  0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 44, 40, 184)  736         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 44, 40, 184)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 44, 40, 92)   16928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 22, 20, 92)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 22, 20, 92)   368         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 22, 20, 92)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 22, 20, 48)   4416        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 22, 20, 48)   192         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 22, 20, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 22, 20, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 22, 20, 104)  0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 22, 20, 104)  416         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 22, 20, 104)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 22, 20, 48)   4992        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 22, 20, 48)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 22, 20, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 22, 20, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 22, 20, 116)  0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 22, 20, 116)  464         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 22, 20, 116)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 22, 20, 48)   5568        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 22, 20, 48)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 22, 20, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 22, 20, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 22, 20, 128)  0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 22, 20, 128)  512         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 22, 20, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 22, 20, 48)   6144        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 22, 20, 48)   192         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 22, 20, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 22, 20, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 22, 20, 140)  0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 22, 20, 140)  560         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 22, 20, 140)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 22, 20, 48)   6720        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 22, 20, 48)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 22, 20, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 22, 20, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 22, 20, 152)  0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 22, 20, 152)  608         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 22, 20, 152)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 22, 20, 48)   7296        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 22, 20, 48)   192         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 22, 20, 48)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 22, 20, 12)   5184        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 22, 20, 164)  0           concatenate_23[0][0]             \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 22, 20, 164)  656         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 22, 20, 164)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 22, 20, 48)   7872        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 22, 20, 48)   192         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 22, 20, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 22, 20, 12)   5184        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 22, 20, 176)  0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 22, 20, 176)  704         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 22, 20, 176)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 22, 20, 48)   8448        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 22, 20, 48)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 22, 20, 48)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 22, 20, 12)   5184        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 22, 20, 188)  0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 22, 20, 188)  752         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 22, 20, 188)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 22, 20, 48)   9024        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 22, 20, 48)   192         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 22, 20, 48)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 22, 20, 12)   5184        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 22, 20, 200)  0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 22, 20, 200)  800         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 22, 20, 200)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 22, 20, 48)   9600        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 22, 20, 48)   192         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 22, 20, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 22, 20, 12)   5184        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 22, 20, 212)  0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 22, 20, 212)  848         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 22, 20, 212)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 22, 20, 48)   10176       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 22, 20, 48)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 22, 20, 48)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 22, 20, 12)   5184        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 22, 20, 224)  0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 22, 20, 224)  896         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 22, 20, 224)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 22, 20, 48)   10752       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 22, 20, 48)   192         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 22, 20, 48)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 22, 20, 12)   5184        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 22, 20, 236)  0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 22, 20, 236)  944         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 22, 20, 236)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 22, 20, 48)   11328       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 22, 20, 48)   192         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 22, 20, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 22, 20, 12)   5184        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 22, 20, 248)  0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 22, 20, 248)  992         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 22, 20, 248)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 22, 20, 48)   11904       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 22, 20, 48)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 22, 20, 48)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 22, 20, 12)   5184        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 22, 20, 260)  0           concatenate_31[0][0]             \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 22, 20, 260)  1040        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 22, 20, 260)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 22, 20, 48)   12480       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 22, 20, 48)   192         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 22, 20, 48)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 22, 20, 12)   5184        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 22, 20, 272)  0           concatenate_32[0][0]             \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 22, 20, 272)  1088        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 22, 20, 272)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 22, 20, 48)   13056       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 22, 20, 48)   192         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 22, 20, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 22, 20, 12)   5184        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 22, 20, 284)  0           concatenate_33[0][0]             \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 22, 20, 284)  1136        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 22, 20, 284)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 22, 20, 48)   13632       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 22, 20, 48)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 22, 20, 48)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 22, 20, 12)   5184        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 22, 20, 296)  0           concatenate_34[0][0]             \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 22, 20, 296)  1184        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 22, 20, 296)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 22, 20, 48)   14208       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 22, 20, 48)   192         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 22, 20, 48)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 22, 20, 12)   5184        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 22, 20, 308)  0           concatenate_35[0][0]             \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 22, 20, 308)  1232        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 22, 20, 308)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 22, 20, 48)   14784       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 22, 20, 48)   192         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 22, 20, 48)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 22, 20, 12)   5184        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 22, 20, 320)  0           concatenate_36[0][0]             \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 22, 20, 320)  1280        concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 22, 20, 320)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 22, 20, 48)   15360       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 22, 20, 48)   192         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 22, 20, 48)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 22, 20, 12)   5184        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 22, 20, 332)  0           concatenate_37[0][0]             \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 22, 20, 332)  1328        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 22, 20, 332)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 22, 20, 48)   15936       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 22, 20, 48)   192         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 22, 20, 48)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 22, 20, 12)   5184        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 22, 20, 344)  0           concatenate_38[0][0]             \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 22, 20, 344)  1376        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 22, 20, 344)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 22, 20, 48)   16512       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 22, 20, 48)   192         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 22, 20, 48)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 22, 20, 12)   5184        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 22, 20, 356)  0           concatenate_39[0][0]             \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 22, 20, 356)  1424        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 22, 20, 356)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 22, 20, 48)   17088       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 22, 20, 48)   192         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 22, 20, 48)   0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 22, 20, 12)   5184        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 22, 20, 368)  0           concatenate_40[0][0]             \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 22, 20, 368)  1472        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 22, 20, 368)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 22, 20, 48)   17664       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 22, 20, 48)   192         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 22, 20, 48)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 22, 20, 12)   5184        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 22, 20, 380)  0           concatenate_41[0][0]             \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 22, 20, 380)  1520        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 22, 20, 380)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 22, 20, 48)   18240       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 22, 20, 48)   192         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 22, 20, 48)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 22, 20, 12)   5184        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 22, 20, 392)  0           concatenate_42[0][0]             \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 22, 20, 392)  1568        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 22, 20, 392)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 22, 20, 48)   18816       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 22, 20, 48)   192         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 22, 20, 48)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 22, 20, 12)   5184        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 22, 20, 404)  0           concatenate_43[0][0]             \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 22, 20, 404)  1616        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 22, 20, 404)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 22, 20, 48)   19392       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 22, 20, 48)   192         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 22, 20, 48)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 22, 20, 12)   5184        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 22, 20, 416)  0           concatenate_44[0][0]             \n",
      "                                                                 conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 22, 20, 416)  1664        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 22, 20, 416)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 22, 20, 48)   19968       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 22, 20, 48)   192         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 22, 20, 48)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 22, 20, 12)   5184        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 22, 20, 428)  0           concatenate_45[0][0]             \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 22, 20, 428)  1712        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 22, 20, 428)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 22, 20, 48)   20544       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 22, 20, 48)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 22, 20, 48)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 22, 20, 12)   5184        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 22, 20, 440)  0           concatenate_46[0][0]             \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 22, 20, 440)  1760        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 22, 20, 440)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 22, 20, 48)   21120       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 22, 20, 48)   192         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 22, 20, 48)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 22, 20, 12)   5184        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 22, 20, 452)  0           concatenate_47[0][0]             \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 22, 20, 452)  1808        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 22, 20, 452)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 22, 20, 48)   21696       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 22, 20, 48)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 22, 20, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 22, 20, 12)   5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 22, 20, 464)  0           concatenate_48[0][0]             \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 22, 20, 464)  1856        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 22, 20, 464)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 22, 20, 48)   22272       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 22, 20, 48)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 22, 20, 48)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 22, 20, 12)   5184        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 22, 20, 476)  0           concatenate_49[0][0]             \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 22, 20, 476)  1904        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 22, 20, 476)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 22, 20, 48)   22848       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 22, 20, 48)   192         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 22, 20, 48)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 22, 20, 12)   5184        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 22, 20, 488)  0           concatenate_50[0][0]             \n",
      "                                                                 conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 22, 20, 488)  1952        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 22, 20, 488)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 22, 20, 48)   23424       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 22, 20, 48)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 22, 20, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 22, 20, 12)   5184        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 22, 20, 500)  0           concatenate_51[0][0]             \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 22, 20, 500)  2000        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 22, 20, 500)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 22, 20, 48)   24000       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 22, 20, 48)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 22, 20, 48)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 22, 20, 12)   5184        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 22, 20, 512)  0           concatenate_52[0][0]             \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 22, 20, 512)  2048        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 22, 20, 512)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 22, 20, 48)   24576       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 22, 20, 48)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 22, 20, 48)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 22, 20, 12)   5184        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 22, 20, 524)  0           concatenate_53[0][0]             \n",
      "                                                                 conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 22, 20, 524)  2096        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 22, 20, 524)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 22, 20, 262)  137288      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 11, 10, 262)  0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 11, 10, 262)  1048        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 11, 10, 262)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 11, 10, 48)   12576       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 11, 10, 48)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 11, 10, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 11, 10, 12)   5184        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 11, 10, 274)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 11, 10, 274)  1096        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 11, 10, 274)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 11, 10, 48)   13152       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 11, 10, 48)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 11, 10, 48)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 11, 10, 12)   5184        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 11, 10, 286)  0           concatenate_55[0][0]             \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 11, 10, 286)  1144        concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 11, 10, 286)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 11, 10, 48)   13728       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 11, 10, 48)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 11, 10, 48)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 11, 10, 12)   5184        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 11, 10, 298)  0           concatenate_56[0][0]             \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 11, 10, 298)  1192        concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 11, 10, 298)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 11, 10, 48)   14304       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 11, 10, 48)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 11, 10, 48)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 11, 10, 12)   5184        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 11, 10, 310)  0           concatenate_57[0][0]             \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 11, 10, 310)  1240        concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 11, 10, 310)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 11, 10, 48)   14880       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 11, 10, 48)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 11, 10, 48)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 11, 10, 12)   5184        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 11, 10, 322)  0           concatenate_58[0][0]             \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 11, 10, 322)  1288        concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 11, 10, 322)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 11, 10, 48)   15456       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 11, 10, 48)   192         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 11, 10, 48)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 11, 10, 12)   5184        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 11, 10, 334)  0           concatenate_59[0][0]             \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 11, 10, 334)  1336        concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 11, 10, 334)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 11, 10, 48)   16032       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 11, 10, 48)   192         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 11, 10, 48)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 11, 10, 12)   5184        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 11, 10, 346)  0           concatenate_60[0][0]             \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 11, 10, 346)  1384        concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 11, 10, 346)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 11, 10, 48)   16608       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 11, 10, 48)   192         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 11, 10, 48)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 11, 10, 12)   5184        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 11, 10, 358)  0           concatenate_61[0][0]             \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 11, 10, 358)  1432        concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 11, 10, 358)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 11, 10, 48)   17184       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 11, 10, 48)   192         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 11, 10, 48)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 11, 10, 12)   5184        activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 11, 10, 370)  0           concatenate_62[0][0]             \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 11, 10, 370)  1480        concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 11, 10, 370)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 11, 10, 48)   17760       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 11, 10, 48)   192         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 11, 10, 48)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 11, 10, 12)   5184        activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 11, 10, 382)  0           concatenate_63[0][0]             \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 11, 10, 382)  1528        concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 11, 10, 382)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 11, 10, 48)   18336       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 11, 10, 48)   192         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 11, 10, 48)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 11, 10, 12)   5184        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 11, 10, 394)  0           concatenate_64[0][0]             \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 11, 10, 394)  1576        concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 11, 10, 394)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 11, 10, 48)   18912       activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 11, 10, 48)   192         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 11, 10, 48)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 11, 10, 12)   5184        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 11, 10, 406)  0           concatenate_65[0][0]             \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 11, 10, 406)  1624        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 11, 10, 406)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 11, 10, 48)   19488       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 11, 10, 48)   192         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 11, 10, 48)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 11, 10, 12)   5184        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 11, 10, 418)  0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 11, 10, 418)  1672        concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 11, 10, 418)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 11, 10, 48)   20064       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 11, 10, 48)   192         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 11, 10, 48)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 11, 10, 12)   5184        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 11, 10, 430)  0           concatenate_67[0][0]             \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 11, 10, 430)  1720        concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 11, 10, 430)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 11, 10, 48)   20640       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 11, 10, 48)   192         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 11, 10, 48)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 11, 10, 12)   5184        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 11, 10, 442)  0           concatenate_68[0][0]             \n",
      "                                                                 conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 11, 10, 442)  1768        concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 11, 10, 442)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 11, 10, 48)   21216       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 11, 10, 48)   192         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 11, 10, 48)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 11, 10, 12)   5184        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 11, 10, 454)  0           concatenate_69[0][0]             \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 11, 10, 454)  1816        concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 11, 10, 454)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 11, 10, 48)   21792       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 11, 10, 48)   192         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 11, 10, 48)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 11, 10, 12)   5184        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 11, 10, 466)  0           concatenate_70[0][0]             \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 11, 10, 466)  1864        concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 11, 10, 466)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 11, 10, 48)   22368       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 11, 10, 48)   192         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 11, 10, 48)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 11, 10, 12)   5184        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 11, 10, 478)  0           concatenate_71[0][0]             \n",
      "                                                                 conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 11, 10, 478)  1912        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 11, 10, 478)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 11, 10, 48)   22944       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 11, 10, 48)   192         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 11, 10, 48)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 11, 10, 12)   5184        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 11, 10, 490)  0           concatenate_72[0][0]             \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 11, 10, 490)  1960        concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 11, 10, 490)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 11, 10, 48)   23520       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 11, 10, 48)   192         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 11, 10, 48)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 11, 10, 12)   5184        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 11, 10, 502)  0           concatenate_73[0][0]             \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 11, 10, 502)  2008        concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 11, 10, 502)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 11, 10, 48)   24096       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 11, 10, 48)   192         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 11, 10, 48)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 11, 10, 12)   5184        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 11, 10, 514)  0           concatenate_74[0][0]             \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 11, 10, 514)  2056        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 11, 10, 514)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 11, 10, 48)   24672       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 11, 10, 48)   192         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 11, 10, 48)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 11, 10, 12)   5184        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 11, 10, 526)  0           concatenate_75[0][0]             \n",
      "                                                                 conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 11, 10, 526)  2104        concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 11, 10, 526)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 11, 10, 48)   25248       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 11, 10, 48)   192         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 11, 10, 48)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 11, 10, 12)   5184        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 11, 10, 538)  0           concatenate_76[0][0]             \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 11, 10, 538)  2152        concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 11, 10, 538)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 11, 10, 48)   25824       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 11, 10, 48)   192         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 11, 10, 48)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 11, 10, 12)   5184        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 11, 10, 550)  0           concatenate_77[0][0]             \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 11, 10, 550)  2200        concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "feature (Activation)            (None, 11, 10, 550)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 550)          0           feature[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            2204        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,727,268\n",
      "Trainable params: 1,673,144\n",
      "Non-trainable params: 54,124\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 352, 320, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 176, 160, 64) 3200        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 176, 160, 64) 256         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 176, 160, 64) 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 88, 80, 64)   0           activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res0a_branch2a (Conv2D)         (None, 44, 40, 64)   36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 44, 40, 64)   256         res0a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 44, 40, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 44, 40, 64)   0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 44, 40, 64)   256         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 44, 40, 64)   36928       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 44, 40, 64)   0           batch_normalization_164[0][0]    \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 44, 40, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 44, 40, 64)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 44, 40, 64)   36928       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 44, 40, 64)   256         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 44, 40, 64)   0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 44, 40, 64)   36928       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 44, 40, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 44, 40, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 44, 40, 64)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 44, 40, 64)   36928       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 44, 40, 64)   256         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 44, 40, 64)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 44, 40, 64)   36928       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 44, 40, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 44, 40, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 44, 40, 64)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 22, 20, 128)  73856       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 22, 20, 128)  512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 22, 20, 128)  8320        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 22, 20, 128)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 22, 20, 128)  512         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 22, 20, 128)  147584      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 22, 20, 128)  0           batch_normalization_171[0][0]    \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 22, 20, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 22, 20, 128)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 22, 20, 128)  147584      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 22, 20, 128)  512         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 22, 20, 128)  0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 22, 20, 128)  147584      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 22, 20, 128)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 22, 20, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 22, 20, 128)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 22, 20, 128)  147584      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 22, 20, 128)  512         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 22, 20, 128)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 22, 20, 128)  147584      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 22, 20, 128)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 22, 20, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 22, 20, 128)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 22, 20, 128)  147584      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 22, 20, 128)  512         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 22, 20, 128)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 22, 20, 128)  147584      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 22, 20, 128)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 22, 20, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 22, 20, 128)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 11, 10, 256)  295168      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 11, 10, 256)  1024        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 11, 10, 256)  33024       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 11, 10, 256)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 11, 10, 256)  1024        conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 11, 10, 256)  590080      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 11, 10, 256)  0           batch_normalization_180[0][0]    \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 11, 10, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 11, 10, 256)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 11, 10, 256)  590080      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 11, 10, 256)  1024        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 11, 10, 256)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 11, 10, 256)  590080      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 11, 10, 256)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 11, 10, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 11, 10, 256)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 11, 10, 256)  590080      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 11, 10, 256)  1024        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 11, 10, 256)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 11, 10, 256)  590080      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 11, 10, 256)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 11, 10, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 11, 10, 256)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 11, 10, 256)  590080      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 11, 10, 256)  1024        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 11, 10, 256)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 11, 10, 256)  590080      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 11, 10, 256)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 11, 10, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 11, 10, 256)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 11, 10, 256)  590080      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 11, 10, 256)  1024        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 11, 10, 256)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 11, 10, 256)  590080      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 11, 10, 256)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 11, 10, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 11, 10, 256)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 11, 10, 256)  590080      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 11, 10, 256)  1024        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 11, 10, 256)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 11, 10, 256)  590080      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 11, 10, 256)  0           add_12[0][0]                     \n",
      "                                                                 conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 11, 10, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 11, 10, 256)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 6, 5, 512)    1180160     activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 6, 5, 512)    2048        conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 6, 5, 512)    131584      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 6, 5, 512)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 6, 5, 512)    2048        conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 6, 5, 512)    2359808     activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 5, 512)    0           batch_normalization_193[0][0]    \n",
      "                                                                 conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 6, 5, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 6, 5, 512)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 6, 5, 512)    2359808     activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 6, 5, 512)    2048        conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 6, 5, 512)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 6, 5, 512)    2359808     activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 6, 5, 512)    0           add_14[0][0]                     \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 6, 5, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 6, 5, 512)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 6, 5, 512)    2359808     activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 6, 5, 512)    2048        conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 6, 5, 512)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 6, 5, 512)    2359808     activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 6, 5, 512)    0           add_15[0][0]                     \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 6, 5, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 6, 5, 512)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            2052        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 21,310,404\n",
      "Trainable params: 21,293,252\n",
      "Non-trainable params: 17,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  # specify which GPU(s) to be used\n",
    "\n",
    "vggModel = VGG.VGG19((352,320,1),4) #set up model architecture\n",
    "vggModel.summary()\n",
    "vggModel.load_weights(\"/home/reza/DeepKneeExplainer/resources/old_models/balanced JSN/VGG19-JSNnewbalance-front-0.8896.h5\") #load weights\n",
    "\n",
    "denseNetModel = densenet.DenseNetImageNet161(input_shape=(352,320,1),classes=4, weights=None)\n",
    "denseNetModel.summary()\n",
    "denseNetModel.load_weights(\"/home/reza/DeepKneeExplainer/resources/old_models/balanced JSN/DenseNet161-JSNnewbalance-XRfront-0.8965.h5\")\n",
    "\n",
    "resNetModel = ResNet.ResNet34(input_shape=(352,320,1),classes=4)\n",
    "resNetModel.summary()\n",
    "resNetModel.load_weights(\"/home/reza/DeepKneeExplainer/resources/old_models/balanced JSN/ResNet34-JSNnewbalance-front-0.8395.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:43:50,492 INFO \n",
      "\n",
      "python      version 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "numpy       version 1.18.1\n",
      "tensforflow version 1.14.0\n",
      "keras       version 2.3.1\n",
      "2020-02-17 23:43:50,494 INFO Analyzing model 'vgg19' with 27 layers\n",
      "2020-02-17 23:43:50,542 INFO ### Printing results ###\n",
      "2020-02-17 23:43:52,039 INFO Check: min: 0.03041860037033362, max: 2.2829769998646285, avg: 1.5622423018363436\n",
      "2020-02-17 23:43:52,040 INFO Check compound: min: 0.03041860037033362, max: 1.9394260118351636, avg: 1.311011840157124\n",
      "2020-02-17 23:43:52,041 INFO CheckTF: min: False, max: True, avg: 0.2835820895522388\n",
      "2020-02-17 23:43:52,042 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.29385964912280704\n",
      "2020-02-17 23:43:52,042 INFO Norm: min: 10.328792572021484, max: 20.418109893798828, avg: 15.373451232910156\n",
      "2020-02-17 23:43:52,043 INFO Norm compound: min: 10.328792572021484, max: 20.418109893798828, avg: 15.373451232910156\n",
      "2020-02-17 23:43:52,044 INFO LogNorm: min: 1.0140495300292969, max: 1.3100155591964722, avg: 1.1620326042175293\n",
      "2020-02-17 23:43:52,044 INFO LogNorm compound: min: 1.0140495300292969, max: 1.3100155591964722, avg: 1.1620326042175293\n",
      "2020-02-17 23:43:52,045 INFO Norm X: min: 11.10615062713623, max: 23.21629524230957, avg: 17.161222457885742\n",
      "2020-02-17 23:43:52,046 INFO Norm X compound: min: 11.10615062713623, max: 23.21629524230957, avg: 17.161222457885742\n",
      "2020-02-17 23:43:52,046 INFO LogNorm X: min: 1.0455635786056519, max: 1.3657928705215454, avg: 1.2056782245635986\n",
      "2020-02-17 23:43:52,047 INFO LogNorm X compound: min: 1.0455635786056519, max: 1.3657928705215454, avg: 1.2056782245635986\n",
      "2020-02-17 23:43:52,065 INFO ### Printing results ###\n",
      "2020-02-17 23:43:53,531 INFO Check: min: 0.03041860037033362, max: 2.2829769998646285, avg: 1.5622423018363436\n",
      "2020-02-17 23:43:53,532 INFO Check compound: min: 0.03041860037033362, max: 1.9394260118351636, avg: 1.311011840157124\n",
      "2020-02-17 23:43:53,533 INFO CheckTF: min: False, max: True, avg: 0.2835820895522388\n",
      "2020-02-17 23:43:53,534 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.29385964912280704\n",
      "2020-02-17 23:43:53,535 INFO Norm: min: 10.328792572021484, max: 20.418109893798828, avg: 15.373451232910156\n",
      "2020-02-17 23:43:53,536 INFO Norm compound: min: 10.328792572021484, max: 20.418109893798828, avg: 15.373451232910156\n",
      "2020-02-17 23:43:53,537 INFO LogNorm: min: 1.0140495300292969, max: 1.3100155591964722, avg: 1.1620326042175293\n",
      "2020-02-17 23:43:53,538 INFO LogNorm compound: min: 1.0140495300292969, max: 1.3100155591964722, avg: 1.1620326042175293\n",
      "2020-02-17 23:43:53,539 INFO Norm X: min: 11.10615062713623, max: 23.21629524230957, avg: 17.161222457885742\n",
      "2020-02-17 23:43:53,540 INFO Norm X compound: min: 11.10615062713623, max: 23.21629524230957, avg: 17.161222457885742\n",
      "2020-02-17 23:43:53,541 INFO LogNorm X: min: 1.0455635786056519, max: 1.3657928705215454, avg: 1.2056782245635986\n",
      "2020-02-17 23:43:53,542 INFO LogNorm X compound: min: 1.0455635786056519, max: 1.3657928705215454, avg: 1.2056782245635986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'check': 1.5622423018363436,\n",
       " 'check_compound': 1.311011840157124,\n",
       " 'checkTF': 0.2835820895522388,\n",
       " 'checkTF_compound': 0.29385964912280704,\n",
       " 'norm': 15.373451,\n",
       " 'norm_compound': 15.373451,\n",
       " 'lognorm': 1.1620326,\n",
       " 'lognorm_compound': 1.1620326,\n",
       " 'normX': 17.161222,\n",
       " 'normX_compound': 17.161222,\n",
       " 'lognormX': 1.2056782,\n",
       " 'lognormX_compound': 1.2056782}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggWatcher = ww.WeightWatcher(model=vggModel)\n",
    "results = vggWatcher.analyze()\n",
    "\n",
    "vggWatcher.print_results()\n",
    "vggWatcher.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:43:57,924 INFO Analyzing model 'vgg19' with 27 layers\n",
      "2020-02-17 23:43:57,956 INFO ### Printing results ###\n",
      "2020-02-17 23:43:59,392 INFO Check: min: 0.5231152375539144, max: 2.2829769998646285, avg: 1.5963780696821568\n",
      "2020-02-17 23:43:59,394 INFO Check compound: min: 0.8410260145476288, max: 1.9394260118351636, avg: 1.5433927278298647\n",
      "2020-02-17 23:43:59,395 INFO CheckTF: min: False, max: True, avg: 0.2900763358778626\n",
      "2020-02-17 23:43:59,396 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.34895833333333337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 23, Slice 0: Lognorm: 1.3100155591964722\n",
      "Layer 25, Slice 0: Lognorm: 1.0140495300292969\n"
     ]
    }
   ],
   "source": [
    "vggWatcher.analyze(layers=ww.LAYER_TYPE.CONV2D)\n",
    "\n",
    "for layer_id, result in results.items():\n",
    "    for slice_id, summary in result.items():\n",
    "        if not str(slice_id).isdigit() or \"lognorm\" not in summary:\n",
    "            continue\n",
    "        lognorm = summary[\"lognorm\"]\n",
    "        print(\"Layer {}, Slice {}: Lognorm: {}\".format(layer_id, slice_id, lognorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:44:19,611 INFO \n",
      "\n",
      "python      version 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "numpy       version 1.18.1\n",
      "tensforflow version 1.14.0\n",
      "keras       version 2.3.1\n",
      "2020-02-17 23:44:19,614 INFO Analyzing model 'model_1' with 127 layers\n",
      "2020-02-17 23:44:19,869 INFO ### Printing results ###\n",
      "2020-02-17 23:44:24,032 INFO Check: min: 0.03055666800210663, max: 1.174803615616177, avg: 0.7524212801186786\n",
      "2020-02-17 23:44:24,033 INFO Check compound: min: 0.03055666800210663, max: 1.171422623526532, avg: 0.6695346588121719\n",
      "2020-02-17 23:44:24,034 INFO CheckTF: min: False, max: True, avg: 0.8293515358361775\n",
      "2020-02-17 23:44:24,035 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.7297297297297297\n",
      "2020-02-17 23:44:24,036 INFO Norm: min: 2.481132745742798, max: 18.79686164855957, avg: 8.44815731048584\n",
      "2020-02-17 23:44:24,037 INFO Norm compound: min: 2.522228717803955, max: 18.74276351928711, avg: 8.113859176635742\n",
      "2020-02-17 23:44:24,038 INFO LogNorm: min: 0.3946499824523926, max: 1.2740854024887085, avg: 0.8404216170310974\n",
      "2020-02-17 23:44:24,039 INFO LogNorm compound: min: 0.4017566442489624, max: 1.2728333473205566, avg: 0.8240067958831787\n",
      "2020-02-17 23:44:24,040 INFO Norm X: min: 1.1169742345809937, max: 22.092660903930664, avg: 7.6573662757873535\n",
      "2020-02-17 23:44:24,041 INFO Norm X compound: min: 1.1598626375198364, max: 21.97178077697754, avg: 7.19776725769043\n",
      "2020-02-17 23:44:24,042 INFO LogNorm X: min: 0.048043157905340195, max: 1.3442480564117432, avg: 0.7077904343605042\n",
      "2020-02-17 23:44:24,043 INFO LogNorm X compound: min: 0.06434845924377441, max: 1.3418642282485962, avg: 0.6814104318618774\n",
      "2020-02-17 23:44:24,075 INFO ### Printing results ###\n",
      "2020-02-17 23:44:28,218 INFO Check: min: 0.03055666800210663, max: 1.174803615616177, avg: 0.7524212801186786\n",
      "2020-02-17 23:44:28,219 INFO Check compound: min: 0.03055666800210663, max: 1.171422623526532, avg: 0.6695346588121719\n",
      "2020-02-17 23:44:28,220 INFO CheckTF: min: False, max: True, avg: 0.8293515358361775\n",
      "2020-02-17 23:44:28,221 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.7297297297297297\n",
      "2020-02-17 23:44:28,221 INFO Norm: min: 2.481132745742798, max: 18.79686164855957, avg: 8.44815731048584\n",
      "2020-02-17 23:44:28,222 INFO Norm compound: min: 2.522228717803955, max: 18.74276351928711, avg: 8.113859176635742\n",
      "2020-02-17 23:44:28,223 INFO LogNorm: min: 0.3946499824523926, max: 1.2740854024887085, avg: 0.8404216170310974\n",
      "2020-02-17 23:44:28,224 INFO LogNorm compound: min: 0.4017566442489624, max: 1.2728333473205566, avg: 0.8240067958831787\n",
      "2020-02-17 23:44:28,224 INFO Norm X: min: 1.1169742345809937, max: 22.092660903930664, avg: 7.6573662757873535\n",
      "2020-02-17 23:44:28,225 INFO Norm X compound: min: 1.1598626375198364, max: 21.97178077697754, avg: 7.19776725769043\n",
      "2020-02-17 23:44:28,226 INFO LogNorm X: min: 0.048043157905340195, max: 1.3442480564117432, avg: 0.7077904343605042\n",
      "2020-02-17 23:44:28,226 INFO LogNorm X compound: min: 0.06434845924377441, max: 1.3418642282485962, avg: 0.6814104318618774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'check': 0.7524212801186786,\n",
       " 'check_compound': 0.6695346588121719,\n",
       " 'checkTF': 0.8293515358361775,\n",
       " 'checkTF_compound': 0.7297297297297297,\n",
       " 'norm': 8.448157,\n",
       " 'norm_compound': 8.113859,\n",
       " 'lognorm': 0.8404216,\n",
       " 'lognorm_compound': 0.8240068,\n",
       " 'normX': 7.6573663,\n",
       " 'normX_compound': 7.1977673,\n",
       " 'lognormX': 0.70779043,\n",
       " 'lognormX_compound': 0.68141043}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetWatcher = ww.WeightWatcher(model=resNetModel)\n",
    "results = resnetWatcher.analyze()\n",
    "\n",
    "resnetWatcher.print_results()\n",
    "resnetWatcher.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:44:47,209 INFO Analyzing model 'model_1' with 127 layers\n",
      "2020-02-17 23:44:47,442 INFO ### Printing results ###\n",
      "2020-02-17 23:44:51,547 INFO Check: min: 0.03055666800210663, max: 1.174803615616177, avg: 0.75461311809406\n",
      "2020-02-17 23:44:51,548 INFO Check compound: min: 0.03055666800210663, max: 1.171422623526532, avg: 0.6850104940206393\n",
      "2020-02-17 23:44:51,549 INFO CheckTF: min: False, max: True, avg: 0.8321917808219178\n",
      "2020-02-17 23:44:51,549 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.75\n",
      "2020-02-17 23:44:51,550 INFO Norm: min: 2.481132745742798, max: 18.79686164855957, avg: 8.44815731048584\n",
      "2020-02-17 23:44:51,551 INFO Norm compound: min: 2.522228717803955, max: 18.74276351928711, avg: 8.113859176635742\n",
      "2020-02-17 23:44:51,551 INFO LogNorm: min: 0.3946499824523926, max: 1.2740854024887085, avg: 0.8404216170310974\n",
      "2020-02-17 23:44:51,552 INFO LogNorm compound: min: 0.4017566442489624, max: 1.2728333473205566, avg: 0.8240067958831787\n",
      "2020-02-17 23:44:51,553 INFO Norm X: min: 1.1169742345809937, max: 22.092660903930664, avg: 7.6573662757873535\n",
      "2020-02-17 23:44:51,553 INFO Norm X compound: min: 1.1598626375198364, max: 21.97178077697754, avg: 7.19776725769043\n",
      "2020-02-17 23:44:51,554 INFO LogNorm X: min: 0.048043157905340195, max: 1.3442480564117432, avg: 0.7077904343605042\n",
      "2020-02-17 23:44:51,554 INFO LogNorm X compound: min: 0.06434845924377441, max: 1.3418642282485962, avg: 0.6814104318618774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 5, Slice 0: Lognorm: 0.45505785942077637\n",
      "Layer 5, Slice 1: Lognorm: 0.466656893491745\n",
      "Layer 5, Slice 2: Lognorm: 0.4717792868614197\n",
      "Layer 5, Slice 3: Lognorm: 0.46813076734542847\n",
      "Layer 5, Slice 4: Lognorm: 0.46588632464408875\n",
      "Layer 5, Slice 5: Lognorm: 0.47582072019577026\n",
      "Layer 5, Slice 6: Lognorm: 0.464699387550354\n",
      "Layer 5, Slice 7: Lognorm: 0.4623936414718628\n",
      "Layer 5, Slice 8: Lognorm: 0.46986302733421326\n",
      "Layer 7, Slice 0: Lognorm: 0.457430899143219\n",
      "Layer 10, Slice 0: Lognorm: 0.4125364422798157\n",
      "Layer 10, Slice 1: Lognorm: 0.4140439033508301\n",
      "Layer 10, Slice 2: Lognorm: 0.4220924377441406\n",
      "Layer 10, Slice 3: Lognorm: 0.4108112156391144\n",
      "Layer 10, Slice 4: Lognorm: 0.4176965057849884\n",
      "Layer 10, Slice 5: Lognorm: 0.4095495045185089\n",
      "Layer 10, Slice 6: Lognorm: 0.41007551550865173\n",
      "Layer 10, Slice 7: Lognorm: 0.4107871353626251\n",
      "Layer 10, Slice 8: Lognorm: 0.41786688566207886\n",
      "Layer 14, Slice 0: Lognorm: 0.42499804496765137\n",
      "Layer 14, Slice 1: Lognorm: 0.40750980377197266\n",
      "Layer 14, Slice 2: Lognorm: 0.41395631432533264\n",
      "Layer 14, Slice 3: Lognorm: 0.4231501519680023\n",
      "Layer 14, Slice 4: Lognorm: 0.4018558859825134\n",
      "Layer 14, Slice 5: Lognorm: 0.41360753774642944\n",
      "Layer 14, Slice 6: Lognorm: 0.4224792718887329\n",
      "Layer 14, Slice 7: Lognorm: 0.42628347873687744\n",
      "Layer 14, Slice 8: Lognorm: 0.417827308177948\n",
      "Layer 17, Slice 0: Lognorm: 0.4136447310447693\n",
      "Layer 17, Slice 1: Lognorm: 0.4083113670349121\n",
      "Layer 17, Slice 2: Lognorm: 0.42101094126701355\n",
      "Layer 17, Slice 3: Lognorm: 0.4197181761264801\n",
      "Layer 17, Slice 4: Lognorm: 0.40751951932907104\n",
      "Layer 17, Slice 5: Lognorm: 0.41531604528427124\n",
      "Layer 17, Slice 6: Lognorm: 0.4172665476799011\n",
      "Layer 17, Slice 7: Lognorm: 0.41146034002304077\n",
      "Layer 17, Slice 8: Lognorm: 0.4150124788284302\n",
      "Layer 21, Slice 0: Lognorm: 0.40195217728614807\n",
      "Layer 21, Slice 1: Lognorm: 0.4070086181163788\n",
      "Layer 21, Slice 2: Lognorm: 0.40973103046417236\n",
      "Layer 21, Slice 3: Lognorm: 0.4061116576194763\n",
      "Layer 21, Slice 4: Lognorm: 0.3946499824523926\n",
      "Layer 21, Slice 5: Lognorm: 0.3948496878147125\n",
      "Layer 21, Slice 6: Lognorm: 0.4021182954311371\n",
      "Layer 21, Slice 7: Lognorm: 0.4002382159233093\n",
      "Layer 21, Slice 8: Lognorm: 0.3991500437259674\n",
      "Layer 24, Slice 0: Lognorm: 0.3997442126274109\n",
      "Layer 24, Slice 1: Lognorm: 0.4016261696815491\n",
      "Layer 24, Slice 2: Lognorm: 0.40429621934890747\n",
      "Layer 24, Slice 3: Lognorm: 0.4039909243583679\n",
      "Layer 24, Slice 4: Lognorm: 0.4118358790874481\n",
      "Layer 24, Slice 5: Lognorm: 0.4028964638710022\n",
      "Layer 24, Slice 6: Lognorm: 0.4040057957172394\n",
      "Layer 24, Slice 7: Lognorm: 0.40782538056373596\n",
      "Layer 24, Slice 8: Lognorm: 0.4001040458679199\n",
      "Layer 28, Slice 0: Lognorm: 0.5612004995346069\n",
      "Layer 28, Slice 1: Lognorm: 0.5566765069961548\n",
      "Layer 28, Slice 2: Lognorm: 0.5645307302474976\n",
      "Layer 28, Slice 3: Lognorm: 0.5442777872085571\n",
      "Layer 28, Slice 4: Lognorm: 0.5450095534324646\n",
      "Layer 28, Slice 5: Lognorm: 0.544856607913971\n",
      "Layer 28, Slice 6: Lognorm: 0.5535491108894348\n",
      "Layer 28, Slice 7: Lognorm: 0.548865020275116\n",
      "Layer 28, Slice 8: Lognorm: 0.5468845367431641\n",
      "Layer 30, Slice 0: Lognorm: 0.5974183678627014\n",
      "Layer 33, Slice 0: Lognorm: 0.6966328620910645\n",
      "Layer 33, Slice 1: Lognorm: 0.6965732574462891\n",
      "Layer 33, Slice 2: Lognorm: 0.6989260315895081\n",
      "Layer 33, Slice 3: Lognorm: 0.6961823105812073\n",
      "Layer 33, Slice 4: Lognorm: 0.690949559211731\n",
      "Layer 33, Slice 5: Lognorm: 0.6955418586730957\n",
      "Layer 33, Slice 6: Lognorm: 0.6931976079940796\n",
      "Layer 33, Slice 7: Lognorm: 0.692370593547821\n",
      "Layer 33, Slice 8: Lognorm: 0.6981958150863647\n",
      "Layer 37, Slice 0: Lognorm: 0.6899280548095703\n",
      "Layer 37, Slice 1: Lognorm: 0.6891337633132935\n",
      "Layer 37, Slice 2: Lognorm: 0.6929138898849487\n",
      "Layer 37, Slice 3: Lognorm: 0.6859428882598877\n",
      "Layer 37, Slice 4: Lognorm: 0.6824015378952026\n",
      "Layer 37, Slice 5: Lognorm: 0.6860530972480774\n",
      "Layer 37, Slice 6: Lognorm: 0.6933414936065674\n",
      "Layer 37, Slice 7: Lognorm: 0.6926486492156982\n",
      "Layer 37, Slice 8: Lognorm: 0.6911203265190125\n",
      "Layer 40, Slice 0: Lognorm: 0.6940612196922302\n",
      "Layer 40, Slice 1: Lognorm: 0.6899809241294861\n",
      "Layer 40, Slice 2: Lognorm: 0.6921338438987732\n",
      "Layer 40, Slice 3: Lognorm: 0.6852380037307739\n",
      "Layer 40, Slice 4: Lognorm: 0.6846174001693726\n",
      "Layer 40, Slice 5: Lognorm: 0.6887117028236389\n",
      "Layer 40, Slice 6: Lognorm: 0.6916100382804871\n",
      "Layer 40, Slice 7: Lognorm: 0.6890596747398376\n",
      "Layer 40, Slice 8: Lognorm: 0.6885004639625549\n",
      "Layer 44, Slice 0: Lognorm: 0.6895345449447632\n",
      "Layer 44, Slice 1: Lognorm: 0.6872230172157288\n",
      "Layer 44, Slice 2: Lognorm: 0.6863046288490295\n",
      "Layer 44, Slice 3: Lognorm: 0.684074342250824\n",
      "Layer 44, Slice 4: Lognorm: 0.6796380877494812\n",
      "Layer 44, Slice 5: Lognorm: 0.6862270832061768\n",
      "Layer 44, Slice 6: Lognorm: 0.6889829635620117\n",
      "Layer 44, Slice 7: Lognorm: 0.6832953691482544\n",
      "Layer 44, Slice 8: Lognorm: 0.6876701712608337\n",
      "Layer 47, Slice 0: Lognorm: 0.6858987808227539\n",
      "Layer 47, Slice 1: Lognorm: 0.6854842901229858\n",
      "Layer 47, Slice 2: Lognorm: 0.6837552785873413\n",
      "Layer 47, Slice 3: Lognorm: 0.6881158947944641\n",
      "Layer 47, Slice 4: Lognorm: 0.6830309629440308\n",
      "Layer 47, Slice 5: Lognorm: 0.6878384351730347\n",
      "Layer 47, Slice 6: Lognorm: 0.6843897700309753\n",
      "Layer 47, Slice 7: Lognorm: 0.685117781162262\n",
      "Layer 47, Slice 8: Lognorm: 0.6854130625724792\n",
      "Layer 51, Slice 0: Lognorm: 0.6857607960700989\n",
      "Layer 51, Slice 1: Lognorm: 0.6855573058128357\n",
      "Layer 51, Slice 2: Lognorm: 0.6847688555717468\n",
      "Layer 51, Slice 3: Lognorm: 0.6779119968414307\n",
      "Layer 51, Slice 4: Lognorm: 0.6808596849441528\n",
      "Layer 51, Slice 5: Lognorm: 0.6807131767272949\n",
      "Layer 51, Slice 6: Lognorm: 0.6808498501777649\n",
      "Layer 51, Slice 7: Lognorm: 0.6864469051361084\n",
      "Layer 51, Slice 8: Lognorm: 0.6829983592033386\n",
      "Layer 54, Slice 0: Lognorm: 0.6817869544029236\n",
      "Layer 54, Slice 1: Lognorm: 0.6880894899368286\n",
      "Layer 54, Slice 2: Lognorm: 0.6814453601837158\n",
      "Layer 54, Slice 3: Lognorm: 0.6856974363327026\n",
      "Layer 54, Slice 4: Lognorm: 0.6820504069328308\n",
      "Layer 54, Slice 5: Lognorm: 0.6831361651420593\n",
      "Layer 54, Slice 6: Lognorm: 0.6827602386474609\n",
      "Layer 54, Slice 7: Lognorm: 0.6840139031410217\n",
      "Layer 54, Slice 8: Lognorm: 0.6813967823982239\n",
      "Layer 58, Slice 0: Lognorm: 0.8478434085845947\n",
      "Layer 58, Slice 1: Lognorm: 0.8462831377983093\n",
      "Layer 58, Slice 2: Lognorm: 0.8478826880455017\n",
      "Layer 58, Slice 3: Lognorm: 0.846968948841095\n",
      "Layer 58, Slice 4: Lognorm: 0.8411282300949097\n",
      "Layer 58, Slice 5: Lognorm: 0.8458948731422424\n",
      "Layer 58, Slice 6: Lognorm: 0.8468871116638184\n",
      "Layer 58, Slice 7: Lognorm: 0.8454727530479431\n",
      "Layer 58, Slice 8: Lognorm: 0.8465520143508911\n",
      "Layer 60, Slice 0: Lognorm: 0.7486953735351562\n",
      "Layer 63, Slice 0: Lognorm: 0.9879443049430847\n",
      "Layer 63, Slice 1: Lognorm: 0.9859838485717773\n",
      "Layer 63, Slice 2: Lognorm: 0.988101601600647\n",
      "Layer 63, Slice 3: Lognorm: 0.9840918779373169\n",
      "Layer 63, Slice 4: Lognorm: 0.9830352663993835\n",
      "Layer 63, Slice 5: Lognorm: 0.9838576316833496\n",
      "Layer 63, Slice 6: Lognorm: 0.9857428073883057\n",
      "Layer 63, Slice 7: Lognorm: 0.9842801690101624\n",
      "Layer 63, Slice 8: Lognorm: 0.9837382435798645\n",
      "Layer 67, Slice 0: Lognorm: 0.9824867248535156\n",
      "Layer 67, Slice 1: Lognorm: 0.9813995957374573\n",
      "Layer 67, Slice 2: Lognorm: 0.9814181327819824\n",
      "Layer 67, Slice 3: Lognorm: 0.9827790260314941\n",
      "Layer 67, Slice 4: Lognorm: 0.9812817573547363\n",
      "Layer 67, Slice 5: Lognorm: 0.982051432132721\n",
      "Layer 67, Slice 6: Lognorm: 0.9831167459487915\n",
      "Layer 67, Slice 7: Lognorm: 0.9809889197349548\n",
      "Layer 67, Slice 8: Lognorm: 0.9802412986755371\n",
      "Layer 70, Slice 0: Lognorm: 0.9822201728820801\n",
      "Layer 70, Slice 1: Lognorm: 0.9830886721611023\n",
      "Layer 70, Slice 2: Lognorm: 0.9816671013832092\n",
      "Layer 70, Slice 3: Lognorm: 0.9816385507583618\n",
      "Layer 70, Slice 4: Lognorm: 0.9808158874511719\n",
      "Layer 70, Slice 5: Lognorm: 0.9795657992362976\n",
      "Layer 70, Slice 6: Lognorm: 0.9791549444198608\n",
      "Layer 70, Slice 7: Lognorm: 0.9798840284347534\n",
      "Layer 70, Slice 8: Lognorm: 0.9795642495155334\n",
      "Layer 74, Slice 0: Lognorm: 0.9764993190765381\n",
      "Layer 74, Slice 1: Lognorm: 0.9800595641136169\n",
      "Layer 74, Slice 2: Lognorm: 0.9799988865852356\n",
      "Layer 74, Slice 3: Lognorm: 0.9809131026268005\n",
      "Layer 74, Slice 4: Lognorm: 0.9784494638442993\n",
      "Layer 74, Slice 5: Lognorm: 0.9776816368103027\n",
      "Layer 74, Slice 6: Lognorm: 0.9787678718566895\n",
      "Layer 74, Slice 7: Lognorm: 0.9786266088485718\n",
      "Layer 74, Slice 8: Lognorm: 0.9791975021362305\n",
      "Layer 77, Slice 0: Lognorm: 0.9778372049331665\n",
      "Layer 77, Slice 1: Lognorm: 0.9787802696228027\n",
      "Layer 77, Slice 2: Lognorm: 0.9784409403800964\n",
      "Layer 77, Slice 3: Lognorm: 0.978242039680481\n",
      "Layer 77, Slice 4: Lognorm: 0.9772581458091736\n",
      "Layer 77, Slice 5: Lognorm: 0.9781072735786438\n",
      "Layer 77, Slice 6: Lognorm: 0.9772962927818298\n",
      "Layer 77, Slice 7: Lognorm: 0.9748155474662781\n",
      "Layer 77, Slice 8: Lognorm: 0.9773114919662476\n",
      "Layer 81, Slice 0: Lognorm: 0.9792867302894592\n",
      "Layer 81, Slice 1: Lognorm: 0.9775155782699585\n",
      "Layer 81, Slice 2: Lognorm: 0.9772075414657593\n",
      "Layer 81, Slice 3: Lognorm: 0.9776692986488342\n",
      "Layer 81, Slice 4: Lognorm: 0.9764446020126343\n",
      "Layer 81, Slice 5: Lognorm: 0.9769513607025146\n",
      "Layer 81, Slice 6: Lognorm: 0.9768497943878174\n",
      "Layer 81, Slice 7: Lognorm: 0.9758248925209045\n",
      "Layer 81, Slice 8: Lognorm: 0.9767579436302185\n",
      "Layer 84, Slice 0: Lognorm: 0.9770217537879944\n",
      "Layer 84, Slice 1: Lognorm: 0.9747512936592102\n",
      "Layer 84, Slice 2: Lognorm: 0.9771922826766968\n",
      "Layer 84, Slice 3: Lognorm: 0.976015567779541\n",
      "Layer 84, Slice 4: Lognorm: 0.9747397899627686\n",
      "Layer 84, Slice 5: Lognorm: 0.9754480719566345\n",
      "Layer 84, Slice 6: Lognorm: 0.9763211011886597\n",
      "Layer 84, Slice 7: Lognorm: 0.9753649234771729\n",
      "Layer 84, Slice 8: Lognorm: 0.9754464030265808\n",
      "Layer 88, Slice 0: Lognorm: 0.9763234257698059\n",
      "Layer 88, Slice 1: Lognorm: 0.9747671484947205\n",
      "Layer 88, Slice 2: Lognorm: 0.9748045802116394\n",
      "Layer 88, Slice 3: Lognorm: 0.9765112996101379\n",
      "Layer 88, Slice 4: Lognorm: 0.9759426116943359\n",
      "Layer 88, Slice 5: Lognorm: 0.9768142700195312\n",
      "Layer 88, Slice 6: Lognorm: 0.974631130695343\n",
      "Layer 88, Slice 7: Lognorm: 0.9753078818321228\n",
      "Layer 88, Slice 8: Lognorm: 0.9729016423225403\n",
      "Layer 91, Slice 0: Lognorm: 0.9749536514282227\n",
      "Layer 91, Slice 1: Lognorm: 0.9743894338607788\n",
      "Layer 91, Slice 2: Lognorm: 0.9728537201881409\n",
      "Layer 91, Slice 3: Lognorm: 0.9762727618217468\n",
      "Layer 91, Slice 4: Lognorm: 0.9728793501853943\n",
      "Layer 91, Slice 5: Lognorm: 0.9746965169906616\n",
      "Layer 91, Slice 6: Lognorm: 0.9744367003440857\n",
      "Layer 91, Slice 7: Lognorm: 0.9736433029174805\n",
      "Layer 91, Slice 8: Lognorm: 0.9741383790969849\n",
      "Layer 95, Slice 0: Lognorm: 0.9756685495376587\n",
      "Layer 95, Slice 1: Lognorm: 0.9766563773155212\n",
      "Layer 95, Slice 2: Lognorm: 0.9744968414306641\n",
      "Layer 95, Slice 3: Lognorm: 0.9747304320335388\n",
      "Layer 95, Slice 4: Lognorm: 0.9705085158348083\n",
      "Layer 95, Slice 5: Lognorm: 0.9731041193008423\n",
      "Layer 95, Slice 6: Lognorm: 0.9734323024749756\n",
      "Layer 95, Slice 7: Lognorm: 0.9726981520652771\n",
      "Layer 95, Slice 8: Lognorm: 0.9745941758155823\n",
      "Layer 98, Slice 0: Lognorm: 0.972281813621521\n",
      "Layer 98, Slice 1: Lognorm: 0.973243236541748\n",
      "Layer 98, Slice 2: Lognorm: 0.9733028411865234\n",
      "Layer 98, Slice 3: Lognorm: 0.9763572216033936\n",
      "Layer 98, Slice 4: Lognorm: 0.974152684211731\n",
      "Layer 98, Slice 5: Lognorm: 0.9723134636878967\n",
      "Layer 98, Slice 6: Lognorm: 0.9727137684822083\n",
      "Layer 98, Slice 7: Lognorm: 0.9750518798828125\n",
      "Layer 98, Slice 8: Lognorm: 0.9747016429901123\n",
      "Layer 102, Slice 0: Lognorm: 1.1258713006973267\n",
      "Layer 102, Slice 1: Lognorm: 1.1252448558807373\n",
      "Layer 102, Slice 2: Lognorm: 1.1249980926513672\n",
      "Layer 102, Slice 3: Lognorm: 1.1234960556030273\n",
      "Layer 102, Slice 4: Lognorm: 1.126001238822937\n",
      "Layer 102, Slice 5: Lognorm: 1.1241992712020874\n",
      "Layer 102, Slice 6: Lognorm: 1.1239309310913086\n",
      "Layer 102, Slice 7: Lognorm: 1.1238864660263062\n",
      "Layer 102, Slice 8: Lognorm: 1.124721646308899\n",
      "Layer 104, Slice 0: Lognorm: 0.8933459520339966\n",
      "Layer 107, Slice 0: Lognorm: 1.2730491161346436\n",
      "Layer 107, Slice 1: Lognorm: 1.2740854024887085\n",
      "Layer 107, Slice 2: Lognorm: 1.2729394435882568\n",
      "Layer 107, Slice 3: Lognorm: 1.272223949432373\n",
      "Layer 107, Slice 4: Lognorm: 1.2729064226150513\n",
      "Layer 107, Slice 5: Lognorm: 1.2725892066955566\n",
      "Layer 107, Slice 6: Lognorm: 1.272721529006958\n",
      "Layer 107, Slice 7: Lognorm: 1.2729053497314453\n",
      "Layer 107, Slice 8: Lognorm: 1.2720792293548584\n",
      "Layer 111, Slice 0: Lognorm: 1.2707302570343018\n",
      "Layer 111, Slice 1: Lognorm: 1.272554636001587\n",
      "Layer 111, Slice 2: Lognorm: 1.2707841396331787\n",
      "Layer 111, Slice 3: Lognorm: 1.2726328372955322\n",
      "Layer 111, Slice 4: Lognorm: 1.2721258401870728\n",
      "Layer 111, Slice 5: Lognorm: 1.2726877927780151\n",
      "Layer 111, Slice 6: Lognorm: 1.2718309164047241\n",
      "Layer 111, Slice 7: Lognorm: 1.2722572088241577\n",
      "Layer 111, Slice 8: Lognorm: 1.2725160121917725\n",
      "Layer 114, Slice 0: Lognorm: 1.271831750869751\n",
      "Layer 114, Slice 1: Lognorm: 1.2728395462036133\n",
      "Layer 114, Slice 2: Lognorm: 1.2723405361175537\n",
      "Layer 114, Slice 3: Lognorm: 1.2722866535186768\n",
      "Layer 114, Slice 4: Lognorm: 1.273871660232544\n",
      "Layer 114, Slice 5: Lognorm: 1.2719104290008545\n",
      "Layer 114, Slice 6: Lognorm: 1.2708736658096313\n",
      "Layer 114, Slice 7: Lognorm: 1.271203875541687\n",
      "Layer 114, Slice 8: Lognorm: 1.2720270156860352\n",
      "Layer 118, Slice 0: Lognorm: 1.2725465297698975\n",
      "Layer 118, Slice 1: Lognorm: 1.2721577882766724\n",
      "Layer 118, Slice 2: Lognorm: 1.272374153137207\n",
      "Layer 118, Slice 3: Lognorm: 1.2721879482269287\n",
      "Layer 118, Slice 4: Lognorm: 1.2723016738891602\n",
      "Layer 118, Slice 5: Lognorm: 1.272029161453247\n",
      "Layer 118, Slice 6: Lognorm: 1.2709635496139526\n",
      "Layer 118, Slice 7: Lognorm: 1.2715508937835693\n",
      "Layer 118, Slice 8: Lognorm: 1.2718702554702759\n",
      "Layer 121, Slice 0: Lognorm: 1.272430419921875\n",
      "Layer 121, Slice 1: Lognorm: 1.2719049453735352\n",
      "Layer 121, Slice 2: Lognorm: 1.271252989768982\n",
      "Layer 121, Slice 3: Lognorm: 1.2712174654006958\n",
      "Layer 121, Slice 4: Lognorm: 1.2730131149291992\n",
      "Layer 121, Slice 5: Lognorm: 1.2721664905548096\n",
      "Layer 121, Slice 6: Lognorm: 1.270777940750122\n",
      "Layer 121, Slice 7: Lognorm: 1.2724508047103882\n",
      "Layer 121, Slice 8: Lognorm: 1.2725721597671509\n"
     ]
    }
   ],
   "source": [
    "resnetWatcher.analyze(layers=ww.LAYER_TYPE.CONV2D)\n",
    "\n",
    "for layer_id, result in results.items():\n",
    "    for slice_id, summary in result.items():\n",
    "        if not str(slice_id).isdigit() or \"lognorm\" not in summary:\n",
    "            continue\n",
    "        lognorm = summary[\"lognorm\"]\n",
    "        print(\"Layer {}, Slice {}: Lognorm: {}\".format(layer_id, slice_id, lognorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:45:34,546 INFO \n",
      "\n",
      "python      version 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "numpy       version 1.18.1\n",
      "tensforflow version 1.14.0\n",
      "keras       version 2.3.1\n",
      "2020-02-17 23:45:34,550 INFO Analyzing model 'densenet' with 567 layers\n",
      "2020-02-17 23:45:34,711 INFO ### Printing results ###\n",
      "2020-02-17 23:45:47,756 INFO Check: min: 0.06097311385698125, max: 2.5768312503419826, avg: 1.0410752223320638\n",
      "2020-02-17 23:45:47,757 INFO Check compound: min: 0.06097311385698125, max: 1.9540489048209366, avg: 0.618539129806069\n",
      "2020-02-17 23:45:47,758 INFO CheckTF: min: False, max: True, avg: 0.8863636363636364\n",
      "2020-02-17 23:45:47,758 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.484472049689441\n",
      "2020-02-17 23:45:47,759 INFO Norm: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:45:47,760 INFO Norm compound: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:45:47,761 INFO LogNorm: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:45:47,761 INFO LogNorm compound: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:45:47,762 INFO Norm X: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:45:47,763 INFO Norm X compound: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:45:47,763 INFO LogNorm X: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n",
      "2020-02-17 23:45:47,764 INFO LogNorm X compound: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n",
      "2020-02-17 23:45:47,793 INFO ### Printing results ###\n",
      "2020-02-17 23:46:00,815 INFO Check: min: 0.06097311385698125, max: 2.5768312503419826, avg: 1.0410752223320638\n",
      "2020-02-17 23:46:00,817 INFO Check compound: min: 0.06097311385698125, max: 1.9540489048209366, avg: 0.618539129806069\n",
      "2020-02-17 23:46:00,818 INFO CheckTF: min: False, max: True, avg: 0.8863636363636364\n",
      "2020-02-17 23:46:00,819 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.484472049689441\n",
      "2020-02-17 23:46:00,820 INFO Norm: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:46:00,820 INFO Norm compound: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:46:00,821 INFO LogNorm: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:46:00,822 INFO LogNorm compound: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:46:00,822 INFO Norm X: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:46:00,823 INFO Norm X compound: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:46:00,824 INFO LogNorm X: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n",
      "2020-02-17 23:46:00,824 INFO LogNorm X compound: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'check': 1.0410752223320638,\n",
       " 'check_compound': 0.618539129806069,\n",
       " 'checkTF': 0.8863636363636364,\n",
       " 'checkTF_compound': 0.484472049689441,\n",
       " 'norm': 12.937265,\n",
       " 'norm_compound': 12.937265,\n",
       " 'lognorm': 1.0979404,\n",
       " 'lognorm_compound': 1.0979404,\n",
       " 'normX': 15.923746,\n",
       " 'normX_compound': 15.923746,\n",
       " 'lognormX': 1.1887772,\n",
       " 'lognormX_compound': 1.1887772}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenetWatcher = ww.WeightWatcher(model=denseNetModel)\n",
    "results = densenetWatcher.analyze()\n",
    "\n",
    "densenetWatcher.print_results()\n",
    "densenetWatcher.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:47:03,220 INFO Analyzing model 'densenet' with 567 layers\n",
      "2020-02-17 23:47:03,397 INFO ### Printing results ###\n",
      "2020-02-17 23:47:16,470 INFO Check: min: 0.06097311385698125, max: 2.5768312503419826, avg: 1.0422549530044871\n",
      "2020-02-17 23:47:16,471 INFO Check compound: min: 0.06097311385698125, max: 1.9540489048209366, avg: 0.6217305727395739\n",
      "2020-02-17 23:47:16,472 INFO CheckTF: min: False, max: True, avg: 0.8874841972187105\n",
      "2020-02-17 23:47:16,473 INFO CheckTF compound: min: 0.0, max: 1.0, avg: 0.4875\n",
      "2020-02-17 23:47:16,474 INFO Norm: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:47:16,475 INFO Norm compound: min: 9.715526580810547, max: 16.15900421142578, avg: 12.937265396118164\n",
      "2020-02-17 23:47:16,476 INFO LogNorm: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:47:16,477 INFO LogNorm compound: min: 0.9874663352966309, max: 1.2084145545959473, avg: 1.097940444946289\n",
      "2020-02-17 23:47:16,478 INFO Norm X: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:47:16,480 INFO Norm X compound: min: 12.04697322845459, max: 19.800518035888672, avg: 15.923746109008789\n",
      "2020-02-17 23:47:16,481 INFO LogNorm X: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n",
      "2020-02-17 23:47:16,482 INFO LogNorm X compound: min: 1.0808779001235962, max: 1.296676516532898, avg: 1.188777208328247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 137, Slice 0: Lognorm: 0.9874663352966309\n",
      "Layer 393, Slice 0: Lognorm: 1.2084145545959473\n"
     ]
    }
   ],
   "source": [
    "densenetWatcher.analyze(layers=ww.LAYER_TYPE.CONV2D)\n",
    "\n",
    "for layer_id, result in results.items():\n",
    "    for slice_id, summary in result.items():\n",
    "        if not str(slice_id).isdigit() or \"lognorm\" not in summary:\n",
    "            continue\n",
    "        lognorm = summary[\"lognorm\"]\n",
    "        print(\"Layer {}, Slice {}: Lognorm: {}\".format(layer_id, slice_id, lognorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WeightWatcher helps you choose the best pretrained model for your needs.\n",
    "\n",
    "## You can use WeightWatcher to compare several pretrained models and choose the one with the lowest Log Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
